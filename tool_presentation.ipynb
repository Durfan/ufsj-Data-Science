{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!pip install pandas\n",
    "!pip install numpy\n",
    "!pip install faiss-cpu\n",
    "!pip install sentence-transformers"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model = SentenceTransformer('all-mpnet-base-v2')\n",
    "data_path = \"../data\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# SentenceTransformers\n",
    "SentenceTransformers is a Python framework for state-of-the-art sentence, text and image embeddings. The initial work is described in our paper Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks.\n",
    "\n",
    "# Faiss\n",
    "Faiss is a library for efficient similarity search and clustering of dense vectors. It contains algorithms that search in sets of vectors of any size, up to ones that possibly do not fit in RAM. It also contains supporting code for evaluation and parameter tuning."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def generate_index(data):\n",
    "    encoded_data = model.encode(data)\n",
    "    encoded_data = np.asarray(encoded_data.astype('float32'))\n",
    "    index = faiss.IndexIDMap(faiss.IndexFlatIP(768))\n",
    "    ids = np.array(range(0, len(data)))\n",
    "    ids = np.asarray(ids.astype('int64'))\n",
    "    index.add_with_ids(encoded_data, ids)\n",
    "    faiss.write_index(index, f'{data_path}/sentences.index')\n",
    "\n",
    "def search(query):\n",
    "    index = faiss.read_index(f'{data_path}/sentences.index')\n",
    "    query_vector = model.encode([query])\n",
    "    k = 5\n",
    "    top_k = index.search(query_vector, k)\n",
    "    return top_k[1].tolist()[0]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df = pd.read_csv(f'{data_path}/data_file.csv', sep=\"\\t\")\n",
    "data = df[\"col\"]\n",
    "\n",
    "generate_index(data)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "query = \"string\"\n",
    "\n",
    "search(query)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.7"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit ('.venv': venv)"
  },
  "interpreter": {
   "hash": "37c2e2033182135ea93565dfd32c9353ddc5f689de9bec5408f95769190ebe73"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}